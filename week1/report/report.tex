 \documentclass[a4paper, 10pt, final]{article}

\usepackage{a4wide}

\usepackage{charter}
\usepackage{verbatim}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
%\usepackage[integrals]{wasysym}
%\usepackage{mathrsfs}
%\usepackage[mathcal]{euscript}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{float}
\usepackage[small,bf]{caption}
%\usepackage{xypic}
\usepackage[table]{xcolor}
\usepackage{subfig}
%\usepackage{ulem} %use \normalem after begin document
\usepackage[authoryear]{natbib}

% Settings
\parindent=5pt
\parskip=8pt plus 2pt minus 4pt
\lstset{language=Matlab, basicstyle=\scriptsize,
    showstringspaces=false, numbers=left, stepnumber=1, numberstyle=\tiny, frame=tb}


%% \def\mytitle{Signal and Image Processing 2010}
%% \def\mysubtitle{Handin of mandatory excercise 1}
%% \def\myauthor{Ulrik Bonde}
%% \def\mymail{\mailto{bonde@diku.dk}}
%% \def\mydate{\today}

\title{Statistical Methods for Machine Learning \\ Mandatory Project 1}
\author{Kasper Steenstrup\\Michael Andersen\\Esben Skaarup}
\date{\today}

%% \title{\mytitle}
%% \subtitle{\mysubtitle}

%% \author{\myauthor{} - \mymail}
%% \date{\mydate}

\hypersetup{
colorlinks,%
citecolor=black,%
filecolor=black,%
linkcolor=black,%
urlcolor=black,%
bookmarksopen=false,
pdftitle={Statistical Methods for Machine Learning - Mandatory Project 1},
pdfauthor={Kasper Steenstrup \& Michael Andersen}
}

\begin{document}
\maketitle

\subsection*{Question 1.1 and 1.2}

In figure \ref{fig:q1_1} can be seen the $100$ data points drawn from
the gaussian distribution with $\mu = [1.0~ 1.0]$ and $\Sigma = [0.3~
  0.2; 0.2~ 0.2]$. The correct $\mu$ is blue and $\widehat{\mu}$ is
marked with red. The code can be seen in \ref{text:Code}

\begin{figure}[!htpb]
  \centering
  \includegraphics[width=0.6\textwidth]{images/q1_1}
  \caption{100 data points, correct mean with blue and estimated mean red.}
  \label{fig:q1_1}
\end{figure}

To quantify how much the estimated mean deviates from the correct
mean, we use usual euclidean distance between the two vectors.

Our distance is $0.0392$, which is not very much. This can also be
seen from the drawing, the points are placed really close.

\subsection*{Question 1.3}

\begin{figure}[!htpbpb]
  \centering
  \includegraphics[width=0.6\textwidth]{images/q1_3a}
  \caption{a shows $p(x_1)$ and b shows $p(x_2)$ using 11 bins.}
  \label{fig:q3_3a}
\end{figure}

\begin{figure}[!htpb]
  \centering
  \includegraphics[width=0.6\textwidth]{images/q1_3b}
  \caption{a shows $p(x_1)$ and b shows $p(x_2)$ using 5 bins.}
  \label{fig:q3_3b}
\end{figure}

\begin{figure}[!htpb]
  \centering
  \includegraphics[width=0.6\textwidth]{images/q1_3c}
  \caption{a shows $p(x_1)$ and b shows $p(x_2)$ using 25 bins.}
  \label{fig:q3_3c}
\end{figure}

There is no best way to select the bin width. If it is selected too
small, the resulting density becomes very spiky and unable to capture
the structure of the distribution. Selecting the bin width too large,
can result in bimodal structure of the distribution being lost. So one
needs to use some intermediate value as bin width. In our case,
selecting a total of 11 bins seems to provide a good estimation of the
distribution, as seen in figure \ref{fig:q1_3a}, \ref{fig:q1_3b}, and \ref{fig:q1_3c}.

\subsection*{Question 1.4}

From the figures \ref{fig:q1_4_100}-\ref{fig:q1_4_10000_b20} it can be seen that
the gaussian distribution is rotated because the $\Sigma$-matrix different
values in the diagonal. The figures show the same tendency as in question 1.3
and can be solved by looking at the figures and selecting appropriate bin
numbers.

\begin{figure}[!htpb]
  \centering
  \includegraphics[width=0.6\textwidth]{images/q1_4_100}
  \caption{Shows 3d histogram of 100 datapoints using $10$x$10$ bins}
  \label{fig:q4_4_100}
\end{figure}

\begin{figure}[!htpb]
  \centering
  \includegraphics[width=0.6\textwidth]{images/q1_4_1000}
  \caption{Shows 3d histogram of 1000 datapoints using $10$x$10$ bins}
  \label{fig:q4_4_1000}
\end{figure}

\begin{figure}[!htpb]
  \centering
  \includegraphics[width=0.6\textwidth]{images/q1_4_10000}
  \caption{Shows 3d histogram of 10000 datapoints using $10$x$10$ bins}
  \label{fig:q4_4_10000}
\end{figure}

\begin{figure}[!htpb]
  \centering
  \includegraphics[width=0.6\textwidth]{images/q1_4_10000_b15}
  \caption{Shows 3d histogram of 10000 datapoints using $15$x$15$ bins}
  \label{fig:q4_4_10000_b15}
\end{figure}

\begin{figure}[!htpb]
  \centering
  \includegraphics[width=0.6\textwidth]{images/q1_4_10000_b20}
  \caption{Shows 3d histogram of 10000 datapoints using $20$x$20$ bins}
  \label{fig:q4_4_10000_b20}
\end{figure}

\subsection*{Question 1.5}
In graph \ref{fig:q5} shows the difference between $\mu _y$, $\hat{y}$ convergence to 0 as $L -> \infty$

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.6\textwidth]{images/q5_L10_L100_L1000}
  \caption{Shows the difference between $\mu _y$ and $\hat{y}$, at point 10, 100, 1000}
  \label{fig:q5}
\end{figure}

In graph \ref{fig:q5_log} we have takent the log of the difference, and
since the difference is are approximation for at exp function, the
plottet line shot be liner. Bot it isent, becorce of the bade aprox or
the large step size.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.6\textwidth]{images/q5_L10_L100_L1000_log}
  \caption{Shows the logarithm difference between $\mu _y$ and $\hat{y}$, at point 10, 100, 1000}
  \label{fig:q5_log}
\end{figure}

\subsection*{Question 1.6}

The auto-correlation is non-zero, since we have feawer samples, and the
are distributes randomly , if we increase the number of samples L, the
auto-correlation get small, see figure \ref{L10000}.When running the
program menny timse, we get diffrent result, bot the paton is the same.
If we set L to 10000 the auto-correlation get very small, and chaces
less betwin run, se figur \ref{L10000} this is at we ekspectet, since
more sampels, decrices the distens betwine the point.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.6\textwidth]{images/L10000}
  \caption{auto-correlation, when $L = 10000$}
  \label{L10000}
\end{figure}
\newpage
\newpage
\newpage
\newpage
\newpage

%% \begin{figure}
%% \centering
%% \subfloat[]{\includegraphics[width=0.3\textwidth]{images/img00}}
%% \subfloat[]{\includegraphics[width=0.45\textwidth]{images/img00h}}
%% \caption{Original image and histogram, unadjusted}
%% \label{fig:original}
%% \end{figure}


\subsection*{Question 1.8}

The maximum likelihood estimation of the color yields the value $\mu _{ML} = [0.9556~ 0.2994~ 0.2569]$.
This seems reasonable for the red vase, as the red value is much larger than the green and blue ones.
Visualizing the RGB color gives a color very close to the color of the vase.

The covariance matrix is also calculated on the training data:\\
$$\Sigma _{ML} = \left[
\begin {array}{ccc}
0.0082 & 0.0052 & 0.0067\\
\noalign{\medskip}
0.0052 & 0.0171 & 0.0199\\
\noalign{\medskip}
0.0067 & 0.0199 & 0.0241\\
\end {array}
\right]$$
% [0.0082~ 0.0052~ 0.0067; 0.0052~ 0.0171~ 0.0199; 0.0067~ 0.0199~ 0.0241]

The probability for each pixel is visualized in figure \ref{fig:q1_8}.
The shape of the vase is clearly depicted, and no pixels outside the vase are visibly colored.
The lighter colors of the vase are not as accurately identified, especially where the reflections cause the original image to have white parts.
This is expected, as the light colors are underrepresented in the training data, causing the $\mu _{ML}$ to be far from white.

\begin{figure}[!htpb]
  \centering
  \includegraphics[width=0.6\textwidth]{images/kande1_probebility.png}
  \caption{The probability of each pixel being a part of the vase.}
  \label{fig:q1_8}
\end{figure}

\subsection*{Question 1.9}

Calculating the average position gives the location $[238~ 303]$ which is visualized by the red cross in figure \ref{fig:q1_9}.
The location seems to accurately represent the center of the vase.

The spatial covariance is also shown in figure \ref{fig:q1_9}.
The curves are elongated in the direction of the handle of the vase, which seems reasonable.
They do, however, seem more elongated than the actual shape of the vase.

\begin{figure}[!htpb]
  \centering
  \includegraphics[width=0.6\textwidth]{images/kande1.png}
  \caption{The average of the probability of the pixels. The red cross marks the average, and the green lines are isoprobability curves of the gaussian distribution.}
  \label{fig:q1_9}
\end{figure}

\subsection*{Question 1.10}

When running the same code with the other image, the results are less successful, seen in figure \ref{fig:q1_10}.
The maximum likelyhood color is, correctly, much darker, which causes some of the brownish colors of the background to be identified as vase-colored.
As pixels with high probability now exist across the entire image, the average and spread are no longer a good indication of the location of the vase.

We can thus conclude that the method, while successful on some images, can not generally identify objects, as the background can interfere.

\begin{figure}[!htpb]
  \centering
  \includegraphics[width=0.6\textwidth]{images/kande2.png}
  \caption{The same data as in figure \ref{fig:q1_9}, but with the image "kande2.JPG".}
  \label{fig:q1_10}
\end{figure}


\newpage
\subsection*{\label{text:Code}}
\lstinputlisting{../src/probability_and_parameter_estimation.m}
\lstinputlisting{../src/code/case18.m}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Formal stuff

%\bibliographystyle{abbrvnat}
%\bibliography{bibliography}
%\addcontentsline{toc}{chapter}{Litteratur}

\end{document}

% vim: set tw=72 spell spelllang=en:
